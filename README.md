في الكود، يتم استخدام نموذجين مختلفين اعتمادًا على الإعداد:

XGBoost (Extreme Gradient Boosting):
تقنية تعلم آلي قوية تعتمد على الغابات العشوائية (Random Forests) وتعزز الأداء عبر تحسين الأخطاء تدريجيًا.
مناسب للبيانات غير المتوازنة والمعقدة.
Random Forest (في بعض التعديلات):
خوارزمية تعتمد على مجموعة من الأشجار لتصنيف البيانات.
تعمل بشكل جيد مع البيانات البسيطة والمتوازنة.


2. عملية التدريب:
(أ) البيانات المدخلة:
الميزات (Features):
Source: عنوان IP للمصدر (تم تحويله إلى رقم باستخدام hash).
Destination: عنوان IP للوجهة (أيضًا تم تحويله إلى رقم).
Protocol: البروتوكول المستخدم (مثل TCP، UDP).
PacketSize: حجم الحزمة (عدد البايتات).
التصنيفات (Labels):
0 تمثل حركة مرور عادية (Normal).
1 تمثل حركة مرور مشبوهة (Suspicious).
(ب) توازن البيانات باستخدام SMOTE:
تقنية SMOTE (Synthetic Minority Over-sampling Technique) تُستخدم لإنشاء عينات إضافية للفئة الأقل (Suspicious) لتحسين أداء النموذج.
(ج) تحسين النموذج باستخدام Grid Search:
Grid Search:
طريقة تجريبية لتحديد أفضل معلمات النموذج (مثل n_estimators, max_depth).
يجرب جميع التوليفات الممكنة من المعلمات ويختار الأفضل بناءً على الأداء.


يتم التقاط الحزم باستخدام مكتبة Scapy.
الميزات مثل Source, Destination, Protocol, PacketSize تُستخرج من الحزمة.



